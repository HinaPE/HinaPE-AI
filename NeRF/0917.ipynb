{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NeRF: Neural Radiance Fields",
   "id": "9534f501770791a5"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:47.592840Z",
     "start_time": "2024-09-21T00:16:44.765609Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import cv2\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm, trange"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:47.623697Z",
     "start_time": "2024-09-21T00:16:47.596850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "args = {\n",
    "    'config': 'configs/lego.txt',\n",
    "    'expname': 'blender_paper_lego',\n",
    "    'basedir': './logs',\n",
    "    'datadir': './data/nerf_synthetic/lego',\n",
    "    'netdepth': 8,\n",
    "    'netwidth': 256,\n",
    "    'netdepth_fine': 8,\n",
    "    'netwidth_fine': 256,\n",
    "    'N_rand': 1024,\n",
    "    'lrate': 0.0005,\n",
    "    'lrate_decay': 500,\n",
    "    'chunk': 32768,\n",
    "    'netchunk': 65536,\n",
    "    'no_batching': True,\n",
    "    'no_reload': False,\n",
    "    'ft_path': None,\n",
    "    'N_samples': 64,\n",
    "    'N_importance': 128,\n",
    "    'perturb': 1.0,\n",
    "    'use_viewdirs': True,\n",
    "    'i_embed': 0,\n",
    "    'multires': 10,\n",
    "    'multires_views': 4,\n",
    "    'raw_noise_std': 0.0,\n",
    "    'render_only': False,\n",
    "    'render_test': False,\n",
    "    'render_factor': 0,\n",
    "    'precrop_iters': 500,\n",
    "    'precrop_frac': 0.5,\n",
    "    'dataset_type': 'blender',\n",
    "    'testskip': 8,\n",
    "    'shape': 'greek',\n",
    "    'white_bkgd': True,\n",
    "    'half_res': True,\n",
    "    'factor': 8,\n",
    "    'no_ndc': False,\n",
    "    'lindisp': False,\n",
    "    'spherify': False,\n",
    "    'llffhold': 8,\n",
    "    'i_print': 100,\n",
    "    'i_img': 500,\n",
    "    'i_weights': 10000,\n",
    "    'i_testset': 50000,\n",
    "    'i_video': 50000\n",
    "}\n",
    "args = argparse.Namespace(**args)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device('cuda')\n",
    "torch.set_default_dtype(torch.float32)"
   ],
   "id": "fd66c4dd127ffdb8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:47.642422Z",
     "start_time": "2024-09-21T00:16:47.634569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trans_t = lambda t: torch.tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 1, t],\n",
    "    [0, 0, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "rot_phi = lambda phi: torch.tensor([\n",
    "    [1, 0, 0, 0],\n",
    "    [0, np.cos(phi), -np.sin(phi), 0],\n",
    "    [0, np.sin(phi), np.cos(phi), 0],\n",
    "    [0, 0, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "rot_theta = lambda th: torch.tensor([\n",
    "    [np.cos(th), 0, -np.sin(th), 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [np.sin(th), 0, np.cos(th), 0],\n",
    "    [0, 0, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi / 180. * np.pi) @ c2w\n",
    "    c2w = rot_theta(theta / 180. * np.pi) @ c2w\n",
    "    c2w = torch.tensor(np.array([[-1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1]]), dtype=torch.float32) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "def get_embedder(multires: int):\n",
    "    include_input = True\n",
    "    input_dims = 3\n",
    "    max_freq_log2 = multires - 1\n",
    "    num_freqs = multires\n",
    "    log_sampling = True\n",
    "    periodic_fns = [torch.sin, torch.cos]\n",
    "\n",
    "    embed_fns = []\n",
    "    out_dim = 0\n",
    "    if include_input:\n",
    "        embed_fns.append(lambda x: x)\n",
    "        out_dim += input_dims\n",
    "    if log_sampling:\n",
    "        freq_bands = 2. ** torch.linspace(0., max_freq_log2, steps=num_freqs)\n",
    "    else:\n",
    "        freq_bands = torch.linspace(2. ** 0., 2. ** max_freq_log2, steps=num_freqs)\n",
    "\n",
    "    for _freq in freq_bands:\n",
    "        for _p_fn in periodic_fns:\n",
    "            embed_fns.append(lambda x, p_fn=_p_fn, freq=_freq: p_fn(x * freq))\n",
    "            out_dim += input_dims\n",
    "\n",
    "    return lambda x: torch.cat([fn(x) for fn in embed_fns], -1), out_dim"
   ],
   "id": "95e32b1e2d8b3e4a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup Log System",
   "id": "556b0a4394f7d07e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:47.653670Z",
     "start_time": "2024-09-21T00:16:47.648604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.makedirs(os.path.normpath(os.path.join(args.basedir, args.expname)), exist_ok=True)\n",
    "with open(os.path.normpath(os.path.join(args.basedir, args.expname, 'args.txt')), 'w') as file:\n",
    "    for arg in sorted(vars(args)):\n",
    "        attr = getattr(args, arg)\n",
    "        file.write('{} = {}\\n'.format(arg, attr))\n",
    "if args.config is not None:\n",
    "    with open(os.path.normpath(os.path.join(args.basedir, args.expname, 'config.txt')), 'w') as file:\n",
    "        file.write(open(args.config, 'r').read())"
   ],
   "id": "f061208b3994f8bd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Images and Poses",
   "id": "cefec6ada029e44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:52.775574Z",
     "start_time": "2024-09-21T00:16:47.660002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metas = {}\n",
    "for _ in ['train', 'val', 'test']:\n",
    "    with open(os.path.normpath(os.path.join(args.datadir, 'transforms_{}.json'.format(_))), 'r') as fp:\n",
    "        metas[_] = json.load(fp)\n",
    "\n",
    "_images = []\n",
    "_poses = []\n",
    "_counts = [0]\n",
    "for _ in ['train', 'val', 'test']:\n",
    "    _img_array = []\n",
    "    _pose_array = []\n",
    "    for frame in metas[_]['frames'][::(1 if _ == 'train' else args.testskip)]:\n",
    "        _img_array.append(\n",
    "            imageio.imread(os.path.normpath(os.path.join(args.datadir, frame['file_path'] + '.png'))))\n",
    "        _pose_array.append(np.array(frame['transform_matrix']))\n",
    "    _counts.append(_counts[-1] + len(_img_array))\n",
    "    _images.append((np.array(_img_array) / 255.).astype(np.float32))\n",
    "    _poses.append(np.array(_pose_array).astype(np.float32))\n",
    "\n",
    "images_concatenated = np.concatenate(_images, 0)\n",
    "poses_concatenated = np.concatenate(_poses, 0)\n",
    "\n",
    "width, height = images_concatenated.shape[1:3]\n",
    "near, far = 2., 6.\n",
    "focal = .5 * width / np.tan(.5 * float(metas['train']['camera_angle_x']))\n",
    "i_train, i_val, i_test = [np.arange(_counts[i], _counts[i + 1]) for i in range(3)]\n",
    "K = np.array([\n",
    "    [focal, 0, 0.5 * width],\n",
    "    [0, focal, 0.5 * height],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "\n",
    "if args.half_res:\n",
    "    width = width // 2\n",
    "    height = height // 2\n",
    "    focal = focal / 2.\n",
    "\n",
    "    _ = np.zeros((images_concatenated.shape[0], height, width, 4))\n",
    "    for i, img in enumerate(images_concatenated):\n",
    "        _[i] = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "    images_concatenated = _\n",
    "\n",
    "if args.white_bkgd:\n",
    "    images_concatenated = images_concatenated[..., :3] * images_concatenated[..., -1:] + (\n",
    "            1. - images_concatenated[..., -1:])\n",
    "else:\n",
    "    images_concatenated = images_concatenated[..., :3]\n",
    "\n",
    "render_poses = torch.stack([pose_spherical(angle, -30.0, 4.0) for angle in np.linspace(-180, 180, 40 + 1)[:-1]], 0)\n",
    "if args.render_test:\n",
    "    render_poses = np.array(poses_concatenated[i_test])"
   ],
   "id": "197e717d5937a795",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create NeRF Model ",
   "id": "bf1440dd2bbec707"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class NeRF(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeRF, self).__init__()"
   ],
   "id": "d6af8c536b3a16db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:52.894701Z",
     "start_time": "2024-09-21T00:16:52.869698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embed_fn = torch.nn.Identity()\n",
    "input_ch = 3\n",
    "if args.i_embed:\n",
    "    embed_fn, input_ch = get_embedder(args.multires)\n",
    "\n",
    "embeddirs_fn = None\n",
    "input_ch_views = 0\n",
    "if args.use_viewdirs:\n",
    "    embeddirs_fn, input_ch = get_embedder(args.multires_views)\n",
    "\n",
    "output_ch = 5 if args.N_importance > 0 else 4"
   ],
   "id": "eec508582810cbb1",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T00:16:52.929072Z",
     "start_time": "2024-09-21T00:16:52.926880Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "24a1f4f011923f9c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
