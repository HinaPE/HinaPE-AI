{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.189585Z",
     "start_time": "2024-09-19T16:06:42.184932Z"
    }
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow, imsave"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.200261Z",
     "start_time": "2024-09-19T16:06:42.197629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = 'DCGAN'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "IMAGE_DIM = (32, 32, 3)"
   ],
   "id": "943bcac89eeef712",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.231496Z",
     "start_time": "2024-09-19T16:06:42.228136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_sample_image(G, n_noise):\n",
    "    \"\"\"\n",
    "        save sample 100 images\n",
    "    \"\"\"\n",
    "    z = torch.randn(10, n_noise).to(DEVICE)\n",
    "    y_hat = G(z).view(10, 3, 28, 28).permute(0, 2, 3, 1)  # (100, 28, 28)\n",
    "    result = (y_hat.detach().cpu().numpy() + 1) / 2.\n",
    "    return result"
   ],
   "id": "a3528e4669601d4f",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.265711Z",
     "start_time": "2024-09-19T16:06:42.260294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Discriminator for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channel=1, num_classes=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # 28 -> 14\n",
    "            nn.Conv2d(in_channel, 512, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 14 -> 7\n",
    "            nn.Conv2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # 7 -> 4\n",
    "            nn.Conv2d(256, 128, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            # \n",
    "            nn.Conv2d(128, 128, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # reshape input, 128 -> 1\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        y_ = self.conv(x)\n",
    "        y_ = y_.view(y_.size(0), -1)\n",
    "        y_ = self.fc(y_)\n",
    "        return y_"
   ],
   "id": "1d590fd5895bbc96",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.308372Z",
     "start_time": "2024-09-19T16:06:42.300420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "        Convolutional Generator for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_channel=1, input_size=100, num_classes=784):\n",
    "        super(Generator, self).__init__()\n",
    "        assert IMAGE_DIM[0] % 2 ** 4 == 0, 'Should be divided 16'\n",
    "        self.init_dim = (IMAGE_DIM[0] // 2 ** 4, IMAGE_DIM[1] // 2 ** 4)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, self.init_dim[0] * self.init_dim[1] * 512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # x2\n",
    "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # x2\n",
    "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # x2\n",
    "            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # x2\n",
    "            nn.ConvTranspose2d(128, out_channel, 4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        y_ = self.fc(x)\n",
    "        y_ = y_.view(y_.size(0), 512, self.init_dim[0], self.init_dim[1])\n",
    "        y_ = self.conv(y_)\n",
    "        return y_"
   ],
   "id": "f6208d7e18c9c33d",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.342026Z",
     "start_time": "2024-09-19T16:06:42.337202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CARS(Dataset):\n",
    "    '''\n",
    "    CARS Dataset\n",
    "    You should download this dataset from below url.\n",
    "    url: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            data_path (str): path to dataset\n",
    "        '''\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.fpaths = sorted(glob.glob(os.path.join(data_path, '*.jpg')))\n",
    "        gray_lst = [266, 1085, 2176, 3048, 3439, 3469, 3539, 4577, 4848, 5177, 5502, 5713, 6947, 7383, 7693, 7774, 8137,\n",
    "                    8144]\n",
    "        for num in gray_lst:\n",
    "            self.fpaths.remove(os.path.join(data_path, '{:05d}.jpg'.format(num)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transform(Image.open(self.fpaths[idx]))\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fpaths)"
   ],
   "id": "b59646e06606f659",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.436734Z",
     "start_time": "2024-09-19T16:06:42.375033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "D = Discriminator(in_channel=IMAGE_DIM[-1]).to(DEVICE)\n",
    "G = Generator(out_channel=IMAGE_DIM[-1]).to(DEVICE)\n",
    "# D.load_state_dict('D_dc.pkl')\n",
    "# G.load_state_dict('G_dc.pkl')"
   ],
   "id": "3955792e468d41fb",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.460749Z",
     "start_time": "2024-09-19T16:06:42.456695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([transforms.Resize((IMAGE_DIM[0], IMAGE_DIM[1])), transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])"
   ],
   "id": "1296f81384a60df2",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.515272Z",
     "start_time": "2024-09-19T16:06:42.484051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import kaggle\n",
    "# kaggle.api.dataset_download_files('rickyyyyyyy/torchvision-stanford-cars', path='./cars', unzip=True)\n",
    "dataset = CARS(data_path='./stanford_cars/cars_train', transform=transform)"
   ],
   "id": "1e743cf44c3938d3",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.543701Z",
     "start_time": "2024-09-19T16:06:42.540994Z"
    }
   },
   "cell_type": "code",
   "source": "batch_size = 64",
   "id": "6645ee8e5a3e5ad1",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.574349Z",
     "start_time": "2024-09-19T16:06:42.570955Z"
    }
   },
   "cell_type": "code",
   "source": "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8)",
   "id": "5a8e6ffac9243906",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.605312Z",
     "start_time": "2024-09-19T16:06:42.601851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.BCELoss()\n",
    "D_opt = torch.optim.Adam(D.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "G_opt = torch.optim.Adam(G.parameters(), lr=0.001, betas=(0.5, 0.999))"
   ],
   "id": "b67f8e6018f78ff1",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.633078Z",
     "start_time": "2024-09-19T16:06:42.630482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_epoch = 100\n",
    "step = 0\n",
    "n_critic = 1  # for training more k steps about Discriminator\n",
    "n_noise = 100"
   ],
   "id": "276caffe18831b87",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-19T16:06:42.666825Z",
     "start_time": "2024-09-19T16:06:42.663201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "D_labels = torch.ones([batch_size, 1]).to(DEVICE)  # Discriminator Label to real\n",
    "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE)  # Discriminator Label to fake"
   ],
   "id": "7816c2789d2a2f0b",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-19T16:06:42.697353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(max_epoch):\n",
    "    for idx, images in enumerate(data_loader):\n",
    "        # Training Discriminator\n",
    "        x = images.to(DEVICE)\n",
    "        x_outputs = D(x)\n",
    "        D_x_loss = criterion(x_outputs, D_labels)\n",
    "\n",
    "        z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
    "        z_outputs = D(G(z))\n",
    "        D_z_loss = criterion(z_outputs, D_fakes)\n",
    "        D_loss = D_x_loss + D_z_loss\n",
    "\n",
    "        D.zero_grad()\n",
    "        D_loss.backward()\n",
    "        D_opt.step()\n",
    "\n",
    "        if step % n_critic == 0:\n",
    "            # Training Generator\n",
    "            z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
    "            z_outputs = D(G(z))\n",
    "            G_loss = criterion(z_outputs, D_labels)\n",
    "\n",
    "            D.zero_grad()\n",
    "            G.zero_grad()\n",
    "            G_loss.backward()\n",
    "            G_opt.step()\n",
    "\n",
    "        if step % 500 == 0:\n",
    "            dt = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "            print('Epoch: {}/{}, Step: {}, D Loss: {:.4f}, G Loss: {:.4f}, Time:{}'.format(epoch, max_epoch, step,\n",
    "                                                                                           D_loss.item(), G_loss.item(),\n",
    "                                                                                           dt))\n",
    "            G.eval()\n",
    "            img = get_sample_image(G, n_noise)\n",
    "            imsave('samples/{}_step{:05d}.jpg'.format(MODEL_NAME, step), img[0])\n",
    "            G.train()\n",
    "        step += 1"
   ],
   "id": "af7b53bf4123a5bf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
